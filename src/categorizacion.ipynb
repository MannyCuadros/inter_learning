{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        var001       var002      var003  month  year     __sexo  __hgt  \\\n",
      "0       168692  U0004802741   4/11/2023      4  2023  Masculino    NaN   \n",
      "1       214287  U0005119913   11/5/2023     11  2023  Masculino    NaN   \n",
      "2       113755  U0004427396   8/13/2022      8  2022  Masculino    NaN   \n",
      "3       202840  U0005038530   9/16/2023      9  2023  Masculino    NaN   \n",
      "4        31544  U0003873327    7/6/2021      7  2021  Masculino    NaN   \n",
      "...        ...          ...         ...    ...   ...        ...    ...   \n",
      "103156  137998  U0004600580  11/26/2022     11  2022   Femenino    NaN   \n",
      "103157   50108  U0003998985  10/21/2021     10  2021   Femenino  101.0   \n",
      "103158   98326  U0004327713    6/3/2022      6  2022  Masculino    NaN   \n",
      "103159  187747  U0004932755    7/1/2023      7  2023  Masculino    NaN   \n",
      "103160  108243  U0004392833   7/20/2022      7  2022   Femenino    NaN   \n",
      "\n",
      "        __temperatura  __pulso  __pas  __pad  __fres  __sat02  __peso  \\\n",
      "0           36.299999     81.0    NaN    NaN     NaN     99.0    42.0   \n",
      "1           36.400002    105.0  185.0   96.0     NaN     99.0     NaN   \n",
      "2           36.200001    101.0    NaN    NaN     NaN     99.0    32.0   \n",
      "3           36.400002    106.0  125.0   99.0     NaN     99.0     NaN   \n",
      "4           36.500000     57.0  118.0   66.0     NaN    100.0     NaN   \n",
      "...               ...      ...    ...    ...     ...      ...     ...   \n",
      "103156      36.299999     74.0  152.0   97.0     NaN     98.0     NaN   \n",
      "103157      36.500000     60.0  143.0   78.0     NaN     98.0     NaN   \n",
      "103158      36.299999     77.0  163.0   77.0     NaN    100.0     NaN   \n",
      "103159      36.400002    112.0  143.0   83.0     NaN     98.0     NaN   \n",
      "103160      36.000000     82.0  167.0   90.0     NaN     98.0     NaN   \n",
      "\n",
      "        __outcome_1  __destino  __outcome_2  __outcome_3 __categorizacion  \n",
      "0               0.0  Domicilio          0.0          0.0               C4  \n",
      "1               0.0  Domicilio          0.0          0.0               C4  \n",
      "2               0.0  Domicilio          0.0          0.0               C3  \n",
      "3               0.0  Domicilio          0.0          0.0               C4  \n",
      "4               0.0  Domicilio          0.0          0.0               C5  \n",
      "...             ...        ...          ...          ...              ...  \n",
      "103156          0.0  Domicilio          0.0          0.0               C3  \n",
      "103157          0.0  Domicilio          0.0          0.0               C2  \n",
      "103158          0.0  Domicilio          0.0          0.0               C4  \n",
      "103159          0.0  Domicilio          0.0          0.0               C4  \n",
      "103160          0.0  Domicilio          0.0          0.0               C3  \n",
      "\n",
      "[103161 rows x 19 columns]\n",
      "Index(['var001', 'var002', 'var003', 'month', 'year', '__sexo', '__hgt',\n",
      "       '__temperatura', '__pulso', '__pas', '__pad', '__fres', '__sat02',\n",
      "       '__peso', '__outcome_1', '__destino', '__outcome_2', '__outcome_3',\n",
      "       '__categorizacion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Base de datos HACQ.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           __sexo  __hgt  __temperatura  __pulso  __pas  __pad  __fres  \\\n",
      "0       Masculino    NaN      36.299999     81.0    NaN    NaN     NaN   \n",
      "1       Masculino    NaN      36.400002    105.0  185.0   96.0     NaN   \n",
      "2       Masculino    NaN      36.200001    101.0    NaN    NaN     NaN   \n",
      "3       Masculino    NaN      36.400002    106.0  125.0   99.0     NaN   \n",
      "4       Masculino    NaN      36.500000     57.0  118.0   66.0     NaN   \n",
      "...           ...    ...            ...      ...    ...    ...     ...   \n",
      "103156   Femenino    NaN      36.299999     74.0  152.0   97.0     NaN   \n",
      "103157   Femenino  101.0      36.500000     60.0  143.0   78.0     NaN   \n",
      "103158  Masculino    NaN      36.299999     77.0  163.0   77.0     NaN   \n",
      "103159  Masculino    NaN      36.400002    112.0  143.0   83.0     NaN   \n",
      "103160   Femenino    NaN      36.000000     82.0  167.0   90.0     NaN   \n",
      "\n",
      "        __sat02  __peso  __outcome_1  __destino  __outcome_2  __outcome_3  \\\n",
      "0          99.0    42.0          0.0  Domicilio          0.0          0.0   \n",
      "1          99.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "2          99.0    32.0          0.0  Domicilio          0.0          0.0   \n",
      "3          99.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "4         100.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "...         ...     ...          ...        ...          ...          ...   \n",
      "103156     98.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "103157     98.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "103158    100.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "103159     98.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "103160     98.0     NaN          0.0  Domicilio          0.0          0.0   \n",
      "\n",
      "       __categorizacion  \n",
      "0                    C4  \n",
      "1                    C4  \n",
      "2                    C3  \n",
      "3                    C4  \n",
      "4                    C5  \n",
      "...                 ...  \n",
      "103156               C3  \n",
      "103157               C2  \n",
      "103158               C4  \n",
      "103159               C4  \n",
      "103160               C3  \n",
      "\n",
      "[103161 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Eliminar las columnas no útiles\n",
    "df_cleaned = df.drop(columns=['var001', 'var002', 'var003', 'month', 'year'])\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4\n",
      "1         4\n",
      "2         3\n",
      "3         4\n",
      "4         5\n",
      "         ..\n",
      "103156    3\n",
      "103157    2\n",
      "103158    4\n",
      "103159    4\n",
      "103160    3\n",
      "Name: __categorizacion, Length: 103161, dtype: int64\n",
      "        __sexo  __hgt  __temperatura  __pulso  __pas  __pad  __fres  __sat02  \\\n",
      "0            1    NaN      36.299999     81.0    NaN    NaN     NaN     99.0   \n",
      "1            1    NaN      36.400002    105.0  185.0   96.0     NaN     99.0   \n",
      "2            1    NaN      36.200001    101.0    NaN    NaN     NaN     99.0   \n",
      "3            1    NaN      36.400002    106.0  125.0   99.0     NaN     99.0   \n",
      "4            1    NaN      36.500000     57.0  118.0   66.0     NaN    100.0   \n",
      "...        ...    ...            ...      ...    ...    ...     ...      ...   \n",
      "103156       0    NaN      36.299999     74.0  152.0   97.0     NaN     98.0   \n",
      "103157       0  101.0      36.500000     60.0  143.0   78.0     NaN     98.0   \n",
      "103158       1    NaN      36.299999     77.0  163.0   77.0     NaN    100.0   \n",
      "103159       1    NaN      36.400002    112.0  143.0   83.0     NaN     98.0   \n",
      "103160       0    NaN      36.000000     82.0  167.0   90.0     NaN     98.0   \n",
      "\n",
      "        __peso  __outcome_1  __destino  __outcome_2  __outcome_3  \n",
      "0         42.0          0.0          2          0.0          0.0  \n",
      "1          NaN          0.0          2          0.0          0.0  \n",
      "2         32.0          0.0          2          0.0          0.0  \n",
      "3          NaN          0.0          2          0.0          0.0  \n",
      "4          NaN          0.0          2          0.0          0.0  \n",
      "...        ...          ...        ...          ...          ...  \n",
      "103156     NaN          0.0          2          0.0          0.0  \n",
      "103157     NaN          0.0          2          0.0          0.0  \n",
      "103158     NaN          0.0          2          0.0          0.0  \n",
      "103159     NaN          0.0          2          0.0          0.0  \n",
      "103160     NaN          0.0          2          0.0          0.0  \n",
      "\n",
      "[103161 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 2: Convertir las columnas categóricas a valores numéricos usando Label Encoding\n",
    "label_encoders = {}\n",
    "for column in ['__sexo', '__destino', '__categorizacion']:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[column] = le.fit_transform(df_cleaned[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Extrae la columna de categorización\n",
    "df_cleaned['__categorizacion'] = df_cleaned['__categorizacion'] + 1\n",
    "df_output = df_cleaned['__categorizacion'].copy()\n",
    "df_cleaned = df_cleaned.drop(['__categorizacion'],axis=1)\n",
    "print(df_output)\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __sexo       __hgt  __temperatura  __pulso       __pas     __pad  \\\n",
      "0            1  184.247016      36.299999     81.0  131.586053  77.40956   \n",
      "1            1  184.247016      36.400002    105.0  185.000000  96.00000   \n",
      "2            1  184.247016      36.200001    101.0  131.586053  77.40956   \n",
      "3            1  184.247016      36.400002    106.0  125.000000  99.00000   \n",
      "4            1  184.247016      36.500000     57.0  118.000000  66.00000   \n",
      "...        ...         ...            ...      ...         ...       ...   \n",
      "103156       0  184.247016      36.299999     74.0  152.000000  97.00000   \n",
      "103157       0  101.000000      36.500000     60.0  143.000000  78.00000   \n",
      "103158       1  184.247016      36.299999     77.0  163.000000  77.00000   \n",
      "103159       1  184.247016      36.400002    112.0  143.000000  83.00000   \n",
      "103160       0  184.247016      36.000000     82.0  167.000000  90.00000   \n",
      "\n",
      "           __fres  __sat02     __peso  __outcome_1  __destino  __outcome_2  \\\n",
      "0       21.035795     99.0  42.000000          0.0          2          0.0   \n",
      "1       21.035795     99.0  29.776061          0.0          2          0.0   \n",
      "2       21.035795     99.0  32.000000          0.0          2          0.0   \n",
      "3       21.035795     99.0  29.776061          0.0          2          0.0   \n",
      "4       21.035795    100.0  29.776061          0.0          2          0.0   \n",
      "...           ...      ...        ...          ...        ...          ...   \n",
      "103156  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103157  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103158  21.035795    100.0  29.776061          0.0          2          0.0   \n",
      "103159  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103160  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "\n",
      "        __outcome_3  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "...             ...  \n",
      "103156          0.0  \n",
      "103157          0.0  \n",
      "103158          0.0  \n",
      "103159          0.0  \n",
      "103160          0.0  \n",
      "\n",
      "[103161 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 3: Manejar los valores faltantes\n",
    "# Rellenar valores numéricos faltantes con la media de la columna\n",
    "for column in df_cleaned.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df_cleaned[column].fillna(df_cleaned[column].mean(), inplace=True)\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          __sexo         __hgt  __temperatura   __pulso     __pas     __pad  \\\n",
      "0       1.093955  2.172054e-15      -0.159434 -0.539508  0.000000  0.000000   \n",
      "1       1.093955  2.172054e-15       0.017166  0.510587  2.612652  1.345863   \n",
      "2       1.093955  2.172054e-15      -0.336025  0.335571  0.000000  0.000000   \n",
      "3       1.093955  2.172054e-15       0.017166  0.554341 -0.322146  1.563050   \n",
      "4       1.093955  2.172054e-15       0.193757 -1.589604 -0.664539 -0.826000   \n",
      "...          ...           ...            ...       ...       ...       ...   \n",
      "103156 -0.914043  2.172054e-15      -0.159434 -0.845786  0.998513  1.418259   \n",
      "103157 -0.914043 -2.120645e+00       0.193757 -1.458342  0.558294  0.042745   \n",
      "103158  1.093955  2.172054e-15      -0.159434 -0.714524  1.536560 -0.029650   \n",
      "103159  1.093955  2.172054e-15       0.017166  0.816865  0.558294  0.404722   \n",
      "103160 -0.914043  2.172054e-15      -0.689216 -0.495754  1.732213  0.911491   \n",
      "\n",
      "        __fres   __sat02        __peso  __outcome_1  __destino  __outcome_2  \\\n",
      "0          0.0  0.274683  1.180038e+00    -0.026244   0.024317    -0.156879   \n",
      "1          0.0  0.274683  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "2          0.0  0.274683  2.146880e-01    -0.026244   0.024317    -0.156879   \n",
      "3          0.0  0.274683  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "4          0.0  0.641641  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "...        ...       ...           ...          ...        ...          ...   \n",
      "103156     0.0 -0.092274  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "103157     0.0 -0.092274  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "103158     0.0  0.641641  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "103159     0.0 -0.092274  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "103160     0.0 -0.092274  6.859223e-16    -0.026244   0.024317    -0.156879   \n",
      "\n",
      "        __outcome_3  \n",
      "0         -0.203124  \n",
      "1         -0.203124  \n",
      "2         -0.203124  \n",
      "3         -0.203124  \n",
      "4         -0.203124  \n",
      "...             ...  \n",
      "103156    -0.203124  \n",
      "103157    -0.203124  \n",
      "103158    -0.203124  \n",
      "103159    -0.203124  \n",
      "103160    -0.203124  \n",
      "\n",
      "[103161 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Escalar los datos para que tengan una media de 0 y una desviación estándar de 1\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_cleaned[numeric_columns] = scaler.fit_transform(df_cleaned[numeric_columns])\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo preprocesado se ha guardado en Base de datos HACQ (preprocesada).csv\n"
     ]
    }
   ],
   "source": [
    "# Exportar el DataFrame resultante a un archivo CSV\n",
    "df_cleaned['__categorizacion'] = df_output\n",
    "output_file_path = 'Base de datos HACQ (preprocesada).csv'\n",
    "df_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"El archivo preprocesado se ha guardado en {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO Y EVALUACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Cargar los datos preprocesados\n",
    "# Cargar los datos preprocesados\n",
    "file_path = 'Base de datos HACQ (preprocesada).csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __sexo       __hgt  __temperatura  __pulso       __pas     __pad  \\\n",
      "0            1  184.247016      36.299999     81.0  131.586053  77.40956   \n",
      "1            1  184.247016      36.400002    105.0  185.000000  96.00000   \n",
      "2            1  184.247016      36.200001    101.0  131.586053  77.40956   \n",
      "3            1  184.247016      36.400002    106.0  125.000000  99.00000   \n",
      "4            1  184.247016      36.500000     57.0  118.000000  66.00000   \n",
      "...        ...         ...            ...      ...         ...       ...   \n",
      "103156       0  184.247016      36.299999     74.0  152.000000  97.00000   \n",
      "103157       0  101.000000      36.500000     60.0  143.000000  78.00000   \n",
      "103158       1  184.247016      36.299999     77.0  163.000000  77.00000   \n",
      "103159       1  184.247016      36.400002    112.0  143.000000  83.00000   \n",
      "103160       0  184.247016      36.000000     82.0  167.000000  90.00000   \n",
      "\n",
      "           __fres  __sat02     __peso  __outcome_1  __destino  __outcome_2  \\\n",
      "0       21.035795     99.0  42.000000          0.0          2          0.0   \n",
      "1       21.035795     99.0  29.776061          0.0          2          0.0   \n",
      "2       21.035795     99.0  32.000000          0.0          2          0.0   \n",
      "3       21.035795     99.0  29.776061          0.0          2          0.0   \n",
      "4       21.035795    100.0  29.776061          0.0          2          0.0   \n",
      "...           ...      ...        ...          ...        ...          ...   \n",
      "103156  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103157  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103158  21.035795    100.0  29.776061          0.0          2          0.0   \n",
      "103159  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "103160  21.035795     98.0  29.776061          0.0          2          0.0   \n",
      "\n",
      "        __outcome_3  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "...             ...  \n",
      "103156          0.0  \n",
      "103157          0.0  \n",
      "103158          0.0  \n",
      "103159          0.0  \n",
      "103160          0.0  \n",
      "\n",
      "[103161 rows x 13 columns]\n",
      "0         4\n",
      "1         4\n",
      "2         3\n",
      "3         4\n",
      "4         5\n",
      "         ..\n",
      "103156    3\n",
      "103157    2\n",
      "103158    4\n",
      "103159    4\n",
      "103160    3\n",
      "Name: __categorizacion, Length: 103161, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2 Separar las características de entrada y de salida (objetivo)\n",
    "input = df.drop(columns=['__categorizacion'])\n",
    "output = df['__categorizacion']\n",
    "\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la salida a categorías\n",
    "output = to_categorical(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Dividir los datos en conjuntos de entrenamiento 80% y prueba 20% \n",
    "input_train, input_test, output_train, output_test = train_test_split(input, output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Construir el modelo dela red neuronal (Perceptron multicapa)\n",
    "def MLP_NN():\n",
    "    NumNeurons = 13\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_train.shape[1]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output.shape[1], activation='softmax'))  # Usar 'softmax' para clasificación multiclase\n",
    "\n",
    "    #opt =  keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.1595 - accuracy: 0.4632 - val_loss: 1.1462 - val_accuracy: 0.4760\n",
      "Epoch 2/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.1302 - accuracy: 0.4775 - val_loss: 1.1184 - val_accuracy: 0.4944\n",
      "Epoch 3/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.1063 - accuracy: 0.4866 - val_loss: 1.1027 - val_accuracy: 0.4900\n",
      "Epoch 4/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0852 - accuracy: 0.4984 - val_loss: 1.0913 - val_accuracy: 0.5003\n",
      "Epoch 5/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0764 - accuracy: 0.5049 - val_loss: 1.0825 - val_accuracy: 0.5099\n",
      "Epoch 6/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0732 - accuracy: 0.5042 - val_loss: 1.0767 - val_accuracy: 0.5019\n",
      "Epoch 7/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0676 - accuracy: 0.5078 - val_loss: 1.0762 - val_accuracy: 0.5095\n",
      "Epoch 8/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0678 - accuracy: 0.5084 - val_loss: 1.0724 - val_accuracy: 0.5160\n",
      "Epoch 9/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0662 - accuracy: 0.5086 - val_loss: 1.0677 - val_accuracy: 0.5171\n",
      "Epoch 10/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0671 - accuracy: 0.5053 - val_loss: 1.0704 - val_accuracy: 0.5140\n",
      "Epoch 11/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0649 - accuracy: 0.5096 - val_loss: 1.0673 - val_accuracy: 0.5115\n",
      "Epoch 12/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0631 - accuracy: 0.5098 - val_loss: 1.0693 - val_accuracy: 0.5127\n",
      "Epoch 13/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0635 - accuracy: 0.5082 - val_loss: 1.0672 - val_accuracy: 0.5129\n",
      "Epoch 14/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0630 - accuracy: 0.5079 - val_loss: 1.0645 - val_accuracy: 0.5109\n",
      "Epoch 15/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0599 - accuracy: 0.5103 - val_loss: 1.0720 - val_accuracy: 0.5128\n",
      "Epoch 16/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0594 - accuracy: 0.5136 - val_loss: 1.0630 - val_accuracy: 0.5164\n",
      "Epoch 17/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0590 - accuracy: 0.5135 - val_loss: 1.0672 - val_accuracy: 0.5119\n",
      "Epoch 18/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0587 - accuracy: 0.5133 - val_loss: 1.0724 - val_accuracy: 0.5139\n",
      "Epoch 19/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0573 - accuracy: 0.5122 - val_loss: 1.0600 - val_accuracy: 0.5168\n",
      "Epoch 20/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0564 - accuracy: 0.5144 - val_loss: 1.0647 - val_accuracy: 0.5169\n",
      "Epoch 21/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0542 - accuracy: 0.5130 - val_loss: 1.0590 - val_accuracy: 0.5187\n",
      "Epoch 22/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0555 - accuracy: 0.5142 - val_loss: 1.0655 - val_accuracy: 0.5121\n",
      "Epoch 23/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0533 - accuracy: 0.5148 - val_loss: 1.0605 - val_accuracy: 0.5171\n",
      "Epoch 24/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0562 - accuracy: 0.5122 - val_loss: 1.0661 - val_accuracy: 0.5120\n",
      "Epoch 25/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0536 - accuracy: 0.5136 - val_loss: 1.0545 - val_accuracy: 0.5153\n",
      "Epoch 26/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0536 - accuracy: 0.5138 - val_loss: 1.0590 - val_accuracy: 0.5201\n",
      "Epoch 27/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0528 - accuracy: 0.5165 - val_loss: 1.0596 - val_accuracy: 0.5176\n",
      "Epoch 28/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0525 - accuracy: 0.5127 - val_loss: 1.0584 - val_accuracy: 0.5194\n",
      "Epoch 29/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0524 - accuracy: 0.5145 - val_loss: 1.0581 - val_accuracy: 0.5158\n",
      "Epoch 30/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0498 - accuracy: 0.5167 - val_loss: 1.0551 - val_accuracy: 0.5197\n",
      "Epoch 31/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0504 - accuracy: 0.5161 - val_loss: 1.0862 - val_accuracy: 0.5129\n",
      "Epoch 32/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0491 - accuracy: 0.5172 - val_loss: 1.0605 - val_accuracy: 0.5211\n",
      "Epoch 33/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0506 - accuracy: 0.5165 - val_loss: 1.0549 - val_accuracy: 0.5202\n",
      "Epoch 34/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0464 - accuracy: 0.5195 - val_loss: 1.0578 - val_accuracy: 0.5192\n",
      "Epoch 35/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0461 - accuracy: 0.5185 - val_loss: 1.0533 - val_accuracy: 0.5210\n",
      "Epoch 36/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0446 - accuracy: 0.5188 - val_loss: 1.0587 - val_accuracy: 0.5138\n",
      "Epoch 37/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0431 - accuracy: 0.5201 - val_loss: 1.0472 - val_accuracy: 0.5277\n",
      "Epoch 38/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0433 - accuracy: 0.5195 - val_loss: 1.0466 - val_accuracy: 0.5255\n",
      "Epoch 39/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0427 - accuracy: 0.5210 - val_loss: 1.0595 - val_accuracy: 0.5230\n",
      "Epoch 40/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0428 - accuracy: 0.5230 - val_loss: 1.0568 - val_accuracy: 0.5232\n",
      "Epoch 41/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0427 - accuracy: 0.5217 - val_loss: 1.0457 - val_accuracy: 0.5284\n",
      "Epoch 42/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0411 - accuracy: 0.5220 - val_loss: 1.0497 - val_accuracy: 0.5262\n",
      "Epoch 43/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0398 - accuracy: 0.5219 - val_loss: 1.0467 - val_accuracy: 0.5230\n",
      "Epoch 44/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0398 - accuracy: 0.5240 - val_loss: 1.0515 - val_accuracy: 0.5273\n",
      "Epoch 45/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0397 - accuracy: 0.5231 - val_loss: 1.0519 - val_accuracy: 0.5248\n",
      "Epoch 46/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0382 - accuracy: 0.5250 - val_loss: 1.0423 - val_accuracy: 0.5308\n",
      "Epoch 47/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0375 - accuracy: 0.5221 - val_loss: 1.0447 - val_accuracy: 0.5270\n",
      "Epoch 48/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0382 - accuracy: 0.5234 - val_loss: 1.0523 - val_accuracy: 0.5161\n",
      "Epoch 49/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0388 - accuracy: 0.5238 - val_loss: 1.0470 - val_accuracy: 0.5276\n",
      "Epoch 50/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0394 - accuracy: 0.5221 - val_loss: 1.0448 - val_accuracy: 0.5278\n",
      "Epoch 51/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0370 - accuracy: 0.5228 - val_loss: 1.0447 - val_accuracy: 0.5251\n",
      "Epoch 52/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0371 - accuracy: 0.5257 - val_loss: 1.0429 - val_accuracy: 0.5259\n",
      "Epoch 53/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0367 - accuracy: 0.5250 - val_loss: 1.0442 - val_accuracy: 0.5223\n",
      "Epoch 54/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0348 - accuracy: 0.5263 - val_loss: 1.0479 - val_accuracy: 0.5278\n",
      "Epoch 55/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0360 - accuracy: 0.5267 - val_loss: 1.0413 - val_accuracy: 0.5333\n",
      "Epoch 56/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0351 - accuracy: 0.5253 - val_loss: 1.0470 - val_accuracy: 0.5280\n",
      "Epoch 57/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0353 - accuracy: 0.5239 - val_loss: 1.0544 - val_accuracy: 0.5237\n",
      "Epoch 58/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0340 - accuracy: 0.5254 - val_loss: 1.0518 - val_accuracy: 0.5233\n",
      "Epoch 59/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0342 - accuracy: 0.5264 - val_loss: 1.0587 - val_accuracy: 0.5164\n",
      "Epoch 60/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0326 - accuracy: 0.5269 - val_loss: 1.0430 - val_accuracy: 0.5267\n",
      "Epoch 61/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0349 - accuracy: 0.5268 - val_loss: 1.0424 - val_accuracy: 0.5256\n",
      "Epoch 62/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0350 - accuracy: 0.5254 - val_loss: 1.0502 - val_accuracy: 0.5223\n",
      "Epoch 63/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0331 - accuracy: 0.5265 - val_loss: 1.0586 - val_accuracy: 0.5147\n",
      "Epoch 64/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0332 - accuracy: 0.5268 - val_loss: 1.0493 - val_accuracy: 0.5242\n",
      "Epoch 65/500\n",
      "2064/2064 [==============================] - 2s 1ms/step - loss: 1.0322 - accuracy: 0.5262 - val_loss: 1.0595 - val_accuracy: 0.5219\n",
      "Epoch 66/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0337 - accuracy: 0.5270 - val_loss: 1.0575 - val_accuracy: 0.5194\n",
      "Epoch 67/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0323 - accuracy: 0.5273 - val_loss: 1.0451 - val_accuracy: 0.5253\n",
      "Epoch 68/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0319 - accuracy: 0.5298 - val_loss: 1.0485 - val_accuracy: 0.5225\n",
      "Epoch 69/500\n",
      "2064/2064 [==============================] - 3s 1ms/step - loss: 1.0314 - accuracy: 0.5280 - val_loss: 1.0383 - val_accuracy: 0.5296\n",
      "Epoch 70/500\n",
      "1094/2064 [==============>...............] - ETA: 0s - loss: 1.0287 - accuracy: 0.5295"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      3\u001b[0m network \u001b[38;5;241m=\u001b[39m MLP_NN()\n\u001b[0;32m----> 4\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/tf_utils.py:692\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#5 Entrenar el modelo\n",
    "n_epochs = 500\n",
    "network = MLP_NN()\n",
    "train = network.fit(input_train, output_train, epochs=n_epochs, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 912us/step - loss: 1.0138 - accuracy: 0.5427\n",
      "Precisión en el conjunto de prueba: 0.54\n"
     ]
    }
   ],
   "source": [
    "#6 Evaluar el modelo\n",
    "loss, accuracy = network.evaluate(input_test, output_test)\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 737us/step\n",
      "[[6.50842316e-17 3.58082239e-08 5.23350900e-03 4.34265994e-02\n",
      "  5.33959210e-01 4.17380542e-01]\n",
      " [3.41017102e-12 2.12893399e-04 4.56655361e-02 1.34047508e-01\n",
      "  5.69094241e-01 2.50979841e-01]\n",
      " [2.09899567e-12 6.59740108e-05 1.97786056e-02 1.13861255e-01\n",
      "  3.34936410e-01 5.31357706e-01]\n",
      " ...\n",
      " [7.40153437e-18 2.93922698e-04 3.55640762e-02 2.12846592e-01\n",
      "  5.26152909e-01 2.25142509e-01]\n",
      " [4.96651548e-12 8.04074007e-05 3.21448296e-02 1.18861236e-01\n",
      "  4.84874576e-01 3.64038855e-01]\n",
      " [5.32948126e-19 2.41415878e-03 5.77372968e-01 2.46052369e-01\n",
      "  1.66504592e-01 7.65590323e-03]]\n",
      "[4 4 5 ... 4 4 2]\n",
      "[4 4 5 ... 5 5 3]\n"
     ]
    }
   ],
   "source": [
    "#7 Predicciones\n",
    "output_pred = network.predict(input_test)\n",
    "print(output_pred)\n",
    "output_pred_classes = np.argmax(output_pred, axis=1)\n",
    "print(output_pred_classes)\n",
    "output_test_classes = np.argmax(output_test, axis=1)\n",
    "print(output_test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.35      0.41        48\n",
      "           2       0.56      0.39      0.46      1217\n",
      "           3       0.62      0.33      0.43      3852\n",
      "           4       0.51      0.52      0.52      7947\n",
      "           5       0.55      0.70      0.62      7569\n",
      "\n",
      "    accuracy                           0.54     20633\n",
      "   macro avg       0.55      0.46      0.49     20633\n",
      "weighted avg       0.55      0.54      0.53     20633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8 Generar el reporte de clasificación\n",
    "print(classification_report(output_test_classes, output_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17   16    9    5    1]\n",
      " [  14  480  256  307  160]\n",
      " [   3  231 1259 1453  906]\n",
      " [   1  104  437 4146 3259]\n",
      " [   0   23   62 2189 5295]]\n"
     ]
    }
   ],
   "source": [
    "#9 Matriz de confusión\n",
    "print(confusion_matrix(output_test_classes, output_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
